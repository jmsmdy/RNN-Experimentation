{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# British National Corpus LSTM\n",
    "\n",
    "### Learns a language model capable of generating / autocompleting sentences.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a generator which loads data from storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a minibatch from storage given its index\n",
    "def load_minibatch(index, var):\n",
    "    shape = np.load(os.path.join('DATA', 'MINIBATCHES', f'{index}_shape.npy'))\n",
    "    for i in range(len(shape)):\n",
    "        if var.shape[i] == None:\n",
    "            continue\n",
    "        elif var.shape[i] != shape[i]:\n",
    "            raise ValueError('Shape of minibatch and variable are incompatible')\n",
    "    \n",
    "    indices = np.load(os.path.join('DATA', 'MINIBATCHES', f'{index}_indices.npy'))\n",
    "    values = np.load(os.path.join('DATA', 'MINIBATCHES', f'{index}_values.npy'))\n",
    "    sparse_tensor = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    var.assign(tf.cast(tf.sparse.to_dense(sparse_tensor), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Generator Class\n",
    "class BatchGenerator(object):\n",
    "    def __init__(self, num_batches, hidden_size):\n",
    "        self.num_batches = num_batches\n",
    "        self.current_idx = 0\n",
    "        self.x = tf.Variable(np.zeros([500, 30, 10002]), dtype=tf.float32, shape=[None, 30, 10002])\n",
    "        \n",
    "    def generate(self):\n",
    "        while True:\n",
    "            load_minibatch(self.current_idx, self.x)\n",
    "            self.current_idx = (self.current_idx + 1) % self.num_batches\n",
    "            X = np.stack([np.zeros([500, 10002])] + [self.x[:, i, :].numpy() for i in range(29)], axis=1)\n",
    "            Y = [self.x[:, i, :].numpy() for i in range(30)]\n",
    "            hidden_state_0 = np.zeros((500, hidden_size))\n",
    "            cell_state_0 = np.zeros((500, hidden_size))\n",
    "            yield [[X, hidden_state_0, cell_state_0], Y]\n",
    "            \n",
    "num_batches = 6806\n",
    "batch_generator = BatchGenerator(6806, 128).generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our numberizing dictionary\n",
    "with open(os.path.join('DATA', 'numberize.json'), 'r') as f:\n",
    "    numberize = json.load(f)\n",
    "\n",
    "# Load our reverse-numberizing dictionary\n",
    "with open(os.path.join('DATA', 'reverse_numberize.json'), 'r') as f:\n",
    "    reverse_numberize = json.load(f)\n",
    "\n",
    "# Converts a list of token indices to a sentence string.\n",
    "def verbalize_sentence(numberized_sentence):\n",
    "    words = [reverse_numberize[str(word_number)] for word_number in numberized_sentence if word_number != 10001]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Converts a tensor of vectorized sentences to a list of sentence strings.\n",
    "def verbalize(vectorized_sentences):\n",
    "    numberized_sentences = tf.argmax(vectorized_sentences, axis=2).numpy()\n",
    "    return list(map(verbalize_sentence, numberized_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AIDS ( <UNK> <UNK> <UNK> <UNK> ) is a condition caused by a virus called HIV ( Human <UNK> <UNK> <UNK> ) .',\n",
       " \"This virus affects the body 's defence system so that it can not fight infection .\",\n",
       " 'through <UNK> sexual intercourse with an infected partner .',\n",
       " 'through infected blood or blood products .',\n",
       " 'from an infected mother to her baby .',\n",
       " 'The medical aspects can be cancer , <UNK> , sudden <UNK> , <UNK> , dramatic weight loss or any combination of these .',\n",
       " 'Often infected people are rejected by family and friends , leaving them to face this chronic condition alone .',\n",
       " 'there is no <UNK> or cure currently available .',\n",
       " '10 million people worldwide are infected with HIV .',\n",
       " 'you can be infected for between <UNK> years without <UNK> it .']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Giving an example of the above functions\n",
    "var = tf.Variable(tf.zeros([500, 30, 10002]), dtype=tf.float32, shape=[None, 30, 10002])\n",
    "load_minibatch(0, var)\n",
    "\n",
    "verbalize(var[0:10,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Model, Input\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Lambda, Reshape\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "sequence_length = 30\n",
    "vocab_size = 10002\n",
    "hidden_size = 128\n",
    "\n",
    "Reshape_cell = Reshape((1, vocab_size)) \n",
    "LSTM_cell = LSTM(hidden_size, return_state = True)\n",
    "Dense_cell = Dense(vocab_size, activation='softmax')\n",
    "\n",
    "def LSTM_model(sequence_length, hidden_size, vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    sequence_length -- length of input sequences\n",
    "    hidden_size -- number of hidden units in LSTM cell\n",
    "    vocab_size -- size of vocabulary in corpus \n",
    "    \n",
    "    Returns:\n",
    "    a keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define inputs to LSTM\n",
    "    X = Input(shape=(sequence_length, vocab_size), name='sequence_input')\n",
    "    hidden_state_0 = Input(shape=(hidden_size,), name='hidden_state_0')\n",
    "    cell_state_0 = Input(shape=(hidden_size,), name='cell_state_0')\n",
    "    \n",
    "    hidden_state = hidden_state_0\n",
    "    cell_state = cell_state_0\n",
    "    outputs = []\n",
    "    for t in range(sequence_length):\n",
    "        # Select t-th time slice\n",
    "        x = Lambda(lambda y: y[:, t, :])(X)\n",
    "        # Rehapse and apply LSTM_cell to time slice\n",
    "        x = Reshape_cell(x)\n",
    "        hidden_state, _, cell_state = LSTM_cell(inputs=x, initial_state=[hidden_state, cell_state])\n",
    "        # Apply Dense_cell to output\n",
    "        output = Dense_cell(hidden_state)\n",
    "        outputs.append(output)\n",
    "        \n",
    "    model = Model(inputs=[X, hidden_state_0, cell_state_0], outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = LSTM_model(sequence_length, hidden_size, vocab_size)\n",
    "optimizer = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_per_epoch = 6706\n",
    "num_epochs = 1\n",
    "\n",
    "# Using data given by the batch generator to train the model\n",
    "model.fit_generator(batch_generator, batches_per_epoch, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights after training\n",
    "model.save_weights('model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Model\n",
    "\n",
    "### Generates novel sentences according to the trained langauge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces a probability distribution with a one-hot vector \n",
    "# representing a random choice according to that distribution.\n",
    "\n",
    "def one_hot_random_sample(distribution):\n",
    "    # Modify the distribution to make <UNK> token impossible\n",
    "    mask = 1 - tf.reshape(tf.one_hot(indices=10000, depth=vocab_size), shape=(1,vocab_size))\n",
    "    rescaled_mask = (1.0 - distribution[0, 10000]) * mask\n",
    "    modified_distribution = rescaled_mask * distribution\n",
    "    \n",
    "    # Sample according to the modified distribution\n",
    "    sample_index = tf.random.categorical(tf.math.log(modified_distribution), 1)\n",
    "    result = tf.one_hot(indices=sample_index, depth=vocab_size)\n",
    "    return result\n",
    "\n",
    "# A cell to randomly sample\n",
    "Random_sample_cell = Lambda(one_hot_random_sample)\n",
    "\n",
    "# This model generates random sentences according to the pretrained LSTM\n",
    "def GeneratorModel(hidden_size, vocab_size, sequence_length):\n",
    "    X = Input(shape=(1, vocab_size), name='initial_input')\n",
    "    hidden_state_0 = Input(shape=(hidden_size,), name='hidden_state_0')\n",
    "    cell_state_0 = Input(shape=(hidden_size,), name='cell_state_0')\n",
    "    \n",
    "    hidden_state = hidden_state_0\n",
    "    cell_state = cell_state_0\n",
    "    \n",
    "    outputs = []\n",
    "    x = Lambda(lambda y: y[:, 0, :])(X)\n",
    "    x = Reshape_cell(x)\n",
    "    hidden_state, _, cell_state = LSTM_cell(inputs=x, initial_state=[hidden_state, cell_state])\n",
    "    distribution = Dense_cell(hidden_state)\n",
    "    result = Random_sample_cell(distribution)\n",
    "    outputs.append(result)\n",
    "    for t in range(1, sequence_length):\n",
    "        hidden_state, _, cell_state = LSTM_cell(inputs=result, initial_state=[hidden_state, cell_state])\n",
    "        distribution = Dense_cell(hidden_state)\n",
    "        result = Random_sample_cell(distribution)\n",
    "        outputs.append(result)\n",
    "        \n",
    "    model = Model(inputs=[X, hidden_state_0, cell_state_0], outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "generator_model = GeneratorModel(hidden_size, vocab_size, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodes the output of the generator model into a sentence string.\n",
    "def decode(result):\n",
    "    word_indices = [np.argmax(word_vector) for word_vector in result]\n",
    "    sentence = verbalize_sentence(word_indices)\n",
    "    return sentence\n",
    "\n",
    "# Generates a sentence using the language model\n",
    "def generate_sentence():\n",
    "    X = np.zeros((1,1,vocab_size))\n",
    "    hidden_state_0 = np.zeros((1, hidden_size))\n",
    "    cell_state_0 = np.zeros((1, hidden_size))\n",
    "\n",
    "    result = generator_model.predict([X, hidden_state_0, cell_state_0])\n",
    "    sentence = decode(result)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• .\n",
      ", it is invented out boxes .\n",
      "But one of the arrested within a brass year and contest noted .\n",
      "I we convinced it to these is there .\n",
      "For course that and these motor speaker is that is us to entirely all terms of abuse suffers .\n",
      "And I , you was a bit good start .\n",
      "Not one which has have a look .\n",
      "I 've got my erm touched one .\n",
      "And it 's on so , if if think in these people 'll start .\n",
      "Among the telephone pound miles on error from endless Wednesday of Ireland 's a death of became , but they had them to send , think it .\n",
      "The idea for the law like you can n't do now on the next talents or the meaning walking to yourself .\n",
      "Mum Yes , I you her .\n",
      "That 's need to she , yeah .\n",
      "They do n't reduce them those of the function .\n",
      "If you 're catch about the house , I was trying to the early , that manager 's statistical Grant is also improved .\n",
      "She and Government the head like , in four , ways , especially distribution administrators and Germany , I 'm sure it seemed to trace of particular ( it .\n",
      "‘ Oh there enough to perform what he has to be stone in the contact first thick , darling last phone .\n",
      "eight has money faced into his father will only smoked all here , the next States .\n",
      "It 's heavy public .\n",
      "So he did just felt about it P .\n",
      "They see the warm outside the bath and you 're erm the boots Party .\n",
      "Two these teeth were killed .\n",
      "No you a lot , ’ 's people I do n't know them .\n",
      "At the trial the UK , eight destined .\n",
      "He said the large widespread .\n",
      "‘ is good , c , the almost in being American , ’ said .\n",
      "It was the glance and consumer announced .\n",
      "I can like it had thirty we want them in her .\n",
      "None .\n",
      "‘ I think had just did n't know .\n",
      "Instead we mean why I mean , to think I 'll do n't come out that team four of on old video , the heavy sleep .\n",
      "No problem .\n",
      "It wo n't come out so .\n",
      "No mum and on this year who had got a ‘ I 'll give me out how some there if called my yeah .\n",
      "No , No. bread , it is apparently that 'em .\n",
      "I n't go here .\n",
      "There will not be easy , Games should be eighty for a well bag .\n",
      "I think we always get them exactly she films it .\n",
      "The second was appeared at please .\n",
      "Further all Saturday transmission soon was MPs at nine .\n",
      "I just trying to get past police .\n",
      "No .\n",
      "It is reminded that the bag of palm , Sundays rose to another Gardens and white .\n",
      "Yeah .\n",
      "Some range of school , dad are a bit and overall lighting and she was two nil through a small requirements .\n",
      "Nearly the Opposition .\n",
      "I 're great most sell of the maths which had a part of the 20 defeat .\n",
      "No , like all up the fastest 's three months like active for a nightmare .\n",
      "She name thought , we could she or work .\n",
      "No sister I do n't think that there 's certainly like that was just went before .\n",
      "They are it 's student , with six thousand Billy mm minute .\n",
      "One book does not do turn with the meeting .\n",
      "After the most line of lunch , No that he did not convince about a lane .\n",
      "Old children over the child yourself , I had already come down .\n",
      "Right voice .\n",
      "Ramsey King Front severe proper Force , yellow any hanging ninety VAT on five .\n",
      "'d have a highly lived in this completion easier to armed cost .\n",
      "I find n .\n",
      "Front , not always complete , especially and we take years , he did n't .\n",
      "rebels is , known .\n",
      "During though the who need themselves will be even two as well .\n",
      "owl 1983 .\n",
      "2 was .\n",
      "One rose there .\n",
      "The other initiative dying properly to processing following terminals individual .\n",
      "How those her accounting for the time in Christmas time again , hanging Stop , accident , not Bishop at the garden , including the women on not worth Mrs\n",
      "We thought it had not been deeply on the constructive seasonal three minutes against VAT .\n",
      "At an official models very big Scottish , but yes .\n",
      "Colin 2 , conducted and he gave me . on\n",
      "‘ I do n't think so you get have gone .\n",
      "It 's now a 20 and substantially again and patterns or travelling .\n",
      "A cloud years on normal ah years .\n",
      "more , on that him , however , will let it anything with changing than heavy top he took the west security .\n",
      "‘ You agree more .\n",
      "He if he try to follow .\n",
      "1937 , I go around .\n",
      "Although my set today 's service of black society and boxes but we might be preferably , they had it children .\n",
      "You must have become a place piece of years .\n",
      "You come back again , thank Yeah on a road .\n",
      "I would have a limited an poverty conceptual loss of erm pretty aim a seven authorities , all they saw like , a host good basis if he had been\n",
      "She arrived down yeah things out her , he was just up the principles , and though a mystery chemical Secretary in end to me .\n",
      "convicted then do seems to see that the spare 's way , like to get five Armstrong Belgium .\n",
      "Do n't going out .\n",
      "And this day that he 's one of his face .\n",
      "No .\n",
      "Come , I got my out .\n",
      "So let's have it out down to two Tuesday to sign in newspapers a car optional .\n",
      "Ah .\n",
      "This record .\n",
      "Why had really find the hospital ! and Work says them .\n",
      "Any ha they implications going to the new quantity .\n",
      "and then the powers , I would have jumping them for a weeks to get ways and light .\n",
      "They know them in what must be found at eight .\n",
      "Sir I 'd originally to say and ran indicates that or any of you the ones .\n",
      "He 'd provide ten against director and time , he said Yeah .\n",
      "Sunderland .\n",
      "In them has to help their question Mm and take for the disease .\n",
      "We keep what approaching petrol are mixed available to injured the pitch , now , but there are not a very couple erm and totally T on at motion ,\n",
      "Oh , I do n't come that we 'll see that .\n",
      "Stanley what the decision of the discrimination itself is based in five magazine returns .\n"
     ]
    }
   ],
   "source": [
    "# Generate 100 sentences\n",
    "for i in range(100):\n",
    "    print(generate_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
